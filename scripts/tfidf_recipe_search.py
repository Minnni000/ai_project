import os
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# é¡¯ç¤ºç•¶å‰å·¥ä½œè·¯å¾‘
current_dir = os.getcwd()
print("ğŸ“‚ ç¾åœ¨åŸ·è¡Œä½ç½®ï¼š", current_dir)

# ç›¸å°è·¯å¾‘è¨­å®š
csv_path = "../cleaned_csv/recipe_documents.csv"

# æª”æ¡ˆå­˜åœ¨æª¢æŸ¥
if not os.path.exists(csv_path):
    raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆï¼š{csv_path}")

# è®€å–è³‡æ–™
df = pd.read_csv(csv_path, encoding="utf-8")

# å»ºç«‹æœå°‹èªæ–™ï¼ˆä½¿ç”¨ combined_text æ¬„ä½ï¼‰
corpus = df["combined_text"].fillna("").tolist()

# TF-IDF å‘é‡åŒ–
vectorizer = TfidfVectorizer(token_pattern=r"(?u)\b\w+\b")
X = vectorizer.fit_transform(corpus)


# æœå°‹å‡½å¼
def search_recipe(query: str, top_k: int = 3):
    query_vec = vectorizer.transform([query])
    sim_scores = cosine_similarity(query_vec, X).flatten()
    top_indices = sim_scores.argsort()[::-1][:top_k]
    return df.iloc[top_indices][["name", "ingredients", "steps", "url", "image_path"]]


# æ¸¬è©¦æŸ¥è©¢ï¼šã€Œå°ç™½èœ å»ä»”é­šã€
results = search_recipe("é¦™è‡ è¾£æ¤’ å°ç™½èœ", top_k=3)

# é¡¯ç¤ºçµæœ
for i, row in results.iterrows():
    print(f"ğŸ“Œ é£Ÿè­œåç¨±ï¼š{row['name']}")
    print(f"ğŸ§‚ é£Ÿæï¼š{row['ingredients']}")
    print(f"ğŸ¥¢ æ­¥é©Ÿï¼š{row['steps']}")
    print(f"ğŸ”— ç¶²å€ï¼š{row['url']}")
    print(f"ğŸ–¼ï¸ åœ–ç‰‡ï¼š{row['image_path']}")
    print("-" * 40)
